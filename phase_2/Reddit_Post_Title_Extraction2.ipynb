{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b73e41a",
   "metadata": {},
   "source": [
    "### Install Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dab697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a889fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv('REDDIT_CLIENT_ID')\n",
    "client_secrets = os.getenv('REDDIT_CLIENT_SECRETS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde31e75",
   "metadata": {},
   "source": [
    "### Get Reddit Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90951175-70c0-42a7-9b18-a6f258ce3c93",
   "metadata": {
    "id": "90951175-70c0-42a7-9b18-a6f258ce3c93"
   },
   "outputs": [],
   "source": [
    "# Use praw to get reddit post data\n",
    "\n",
    "# function to get reddit post details\n",
    "def get_post_details(full_link):\n",
    "    post_id = full_link\n",
    "\n",
    "    for _ in range(3):\n",
    "        try:  # Try more times in case rate exceeded\n",
    "            reddit = praw.Reddit(\n",
    "                client_id= client_id,           # use .env file to access\n",
    "                client_secret= client_secrets,  # use .env file to access\n",
    "                user_agent='my_reddit_scraper by u/yourusername')\n",
    "\n",
    "            submission = reddit.submission(id=post_id)\n",
    "            # get submission title, id, score, and number of comments\n",
    "            data = {\n",
    "                'post_id': submission.id,\n",
    "                'post_type': 'NIL',\n",
    "                'created_timestamp': datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'subreddit_id': submission.subreddit_id,\n",
    "                'subreddit_name': submission.subreddit.display_name_prefixed,\n",
    "                'title': submission.title,\n",
    "                'author': submission.author.name if submission.author else 'Not Found',\n",
    "                'author_id': submission.author_fullname if submission.author else 'Not Found',\n",
    "                'comment_count': submission.num_comments,\n",
    "                'vote_score': submission.score,\n",
    "                'post_content': submission.selftext if submission.is_self else submission.url\n",
    "            }\n",
    "            return data\n",
    "        except:\n",
    "            print(f\"FAIL: {post_url}\")\n",
    "            pass\n",
    "    blank_data = {'post_id': post_id, 'post_type': 'Not Found', 'created_timestamp': 'Not Found',\n",
    "                  'subreddit_id': 'Not Found', 'subreddit_name': 'Not Found', 'title': 'Not Found',\n",
    "                  'author': 'Not Found', 'author_id': 'Not Found', 'comment_count': 'Not Found',\n",
    "                  'vote_score': 'Not Found'}\n",
    "    return blank_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af74e4-1db2-4d23-aacc-ed11b1b76873",
   "metadata": {
    "id": "63af74e4-1db2-4d23-aacc-ed11b1b76873",
    "outputId": "a13162c2-d17c-4e42-8c29-96b2b375c908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing a total of 7445 links\n"
     ]
    }
   ],
   "source": [
    "links = pd.read_csv('../data/deberta_v3_labelled_3_ALL.csv').drop_duplicates(subset='link_id')  # Load unique posts\n",
    "links = links['link_id'].tolist()\n",
    "links = [l for l in links if type(l)==str]  # Remove nan\n",
    "\n",
    "# Read previously processed post_ids if exists\n",
    "if os.path.exists('../data/reddit_posts_data.csv'):\n",
    "    existing_df = pd.read_csv('../data/reddit_posts_data.csv', low_memory=False)\n",
    "    existing_df = existing_df[existing_df['subreddit_id'] != \"Not Found\"]  # Try again for Not Found ones\n",
    "    existing_ids = set(existing_df['post_id'].tolist())\n",
    "else:\n",
    "    existing_df = None\n",
    "    existing_ids = set()\n",
    "\n",
    "# filter out links that have already been processed\n",
    "links = [link for link in links if link not in existing_ids]\n",
    "print(f\"Processing a total of {len(links)} links\")\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d53739-b293-4ea3-b496-4bd364d11c09",
   "metadata": {
    "id": "18d53739-b293-4ea3-b496-4bd364d11c09",
    "outputId": "164d5238-92a5-43d0-81cc-c00eba2282de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 min: 2/7445, 0.03%\n",
      "5.0 min: 102/7445, 1.37%\n",
      "10.0 min: 202/7445, 2.71%\n",
      "14.0 min: 302/7445, 4.06%\n",
      "17.0 min: 402/7445, 5.40%\n",
      "21.0 min: 502/7445, 6.74%\n",
      "24.0 min: 602/7445, 8.09%\n",
      "27.0 min: 702/7445, 9.43%\n",
      "31.0 min: 802/7445, 10.77%\n",
      "34.0 min: 902/7445, 12.12%\n",
      "37.0 min: 1002/7445, 13.46%\n",
      "41.0 min: 1102/7445, 14.80%\n",
      "44.0 min: 1202/7445, 16.15%\n",
      "47.0 min: 1302/7445, 17.49%\n",
      "51.0 min: 1402/7445, 18.83%\n",
      "54.0 min: 1502/7445, 20.17%\n",
      "57.0 min: 1602/7445, 21.52%\n",
      "61.0 min: 1702/7445, 22.86%\n",
      "64.0 min: 1802/7445, 24.20%\n",
      "68.0 min: 1902/7445, 25.55%\n",
      "71.0 min: 2002/7445, 26.89%\n",
      "74.0 min: 2102/7445, 28.23%\n",
      "78.0 min: 2202/7445, 29.58%\n",
      "82.0 min: 2302/7445, 30.92%\n",
      "86.0 min: 2402/7445, 32.26%\n",
      "90.0 min: 2502/7445, 33.61%\n",
      "94.0 min: 2602/7445, 34.95%\n",
      "98.0 min: 2702/7445, 36.29%\n",
      "102.0 min: 2802/7445, 37.64%\n",
      "105.0 min: 2902/7445, 38.98%\n",
      "109.0 min: 3002/7445, 40.32%\n",
      "113.0 min: 3102/7445, 41.67%\n",
      "117.0 min: 3202/7445, 43.01%\n",
      "120.0 min: 3302/7445, 44.35%\n",
      "124.0 min: 3402/7445, 45.70%\n",
      "128.0 min: 3502/7445, 47.04%\n",
      "132.0 min: 3602/7445, 48.38%\n",
      "135.0 min: 3702/7445, 49.72%\n",
      "139.0 min: 3802/7445, 51.07%\n",
      "142.0 min: 3902/7445, 52.41%\n",
      "146.0 min: 4002/7445, 53.75%\n",
      "150.0 min: 4102/7445, 55.10%\n",
      "153.0 min: 4202/7445, 56.44%\n",
      "157.0 min: 4302/7445, 57.78%\n",
      "160.0 min: 4402/7445, 59.13%\n",
      "164.0 min: 4502/7445, 60.47%\n",
      "168.0 min: 4602/7445, 61.81%\n",
      "171.0 min: 4702/7445, 63.16%\n",
      "175.0 min: 4802/7445, 64.50%\n",
      "178.0 min: 4902/7445, 65.84%\n",
      "182.0 min: 5002/7445, 67.19%\n",
      "186.0 min: 5102/7445, 68.53%\n",
      "189.0 min: 5202/7445, 69.87%\n",
      "193.0 min: 5302/7445, 71.22%\n",
      "196.0 min: 5402/7445, 72.56%\n",
      "200.0 min: 5502/7445, 73.90%\n",
      "203.0 min: 5602/7445, 75.25%\n",
      "207.0 min: 5702/7445, 76.59%\n",
      "210.0 min: 5802/7445, 77.93%\n",
      "214.0 min: 5902/7445, 79.27%\n",
      "217.0 min: 6002/7445, 80.62%\n",
      "220.0 min: 6102/7445, 81.96%\n",
      "224.0 min: 6202/7445, 83.30%\n",
      "227.0 min: 6302/7445, 84.65%\n",
      "230.0 min: 6402/7445, 85.99%\n",
      "234.0 min: 6502/7445, 87.33%\n",
      "237.0 min: 6602/7445, 88.68%\n",
      "241.0 min: 6702/7445, 90.02%\n",
      "244.0 min: 6802/7445, 91.36%\n",
      "247.0 min: 6902/7445, 92.71%\n",
      "251.0 min: 7002/7445, 94.05%\n",
      "254.0 min: 7102/7445, 95.39%\n",
      "257.0 min: 7202/7445, 96.74%\n",
      "261.0 min: 7302/7445, 98.08%\n",
      "264.0 min: 7402/7445, 99.42%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "i = 0\n",
    "while i < len(links):\n",
    "    full_link = links[i]\n",
    "    i+=1\n",
    "    if i % 100 == 1:  # Print progress and save every 100 entries\n",
    "        try:\n",
    "            if os.path.exists('../data/reddit_posts_data.csv'):\n",
    "                existing_df = pd.read_csv('../data/reddit_posts_data.csv', low_memory=False)\n",
    "            else:\n",
    "                existing_df = None\n",
    "            if existing_df is not None:  # Add new results to existing results and save\n",
    "                pd.concat([existing_df, pd.DataFrame(results)], ignore_index=True).drop_duplicates().to_csv('../data/reddit_posts_data.csv', index=False)\n",
    "            else:\n",
    "                pd.DataFrame(results).drop_duplicates().to_csv('../data/reddit_posts_data.csv', index=False)\n",
    "        except:\n",
    "            pass\n",
    "        print(f\"{(time.time()-start_time)//60} min: {i + 1}/{len(links)}, {(i + 1) / len(links) * 100:.2f}%\")\n",
    "    try:\n",
    "        data = get_post_details(full_link)\n",
    "        results.append(data)\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4bd6e1-991c-4e31-90e1-861793ff1798",
   "metadata": {
    "id": "2c4bd6e1-991c-4e31-90e1-861793ff1798"
   },
   "outputs": [],
   "source": [
    "# One final round of saving\n",
    "if os.path.exists('../data/reddit_posts_data.csv'):\n",
    "    existing_df = pd.read_csv('../data/reddit_posts_data.csv', low_memory=False)\n",
    "else:\n",
    "    existing_df = None\n",
    "if existing_df is not None:\n",
    "    pd.concat([existing_df, pd.DataFrame(results)], ignore_index=True).to_csv('../data/reddit_posts_data.csv', index=False)\n",
    "else:\n",
    "    pd.DataFrame(results).to_csv('../data/reddit_posts_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
